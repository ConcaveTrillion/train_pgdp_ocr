{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from sys import stdout\n",
    "\n",
    "import torch\n",
    "from torch import load as torch_load\n",
    "\n",
    "from doctr.datasets.vocabs import VOCABS\n",
    "from doctr.models import (\n",
    "    crnn_vgg16_bn,\n",
    "    db_resnet50,\n",
    "    detection_predictor,\n",
    "    ocr_predictor,\n",
    "    recognition_predictor,\n",
    ")\n",
    "from pd_book_tools.pgdp.pgdp_results import PGDPExport\n",
    "\n",
    "from data_labeler.ipynb_labeler import IpynbLabeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreadFilter:\n",
    "    def __init__(self, id):\n",
    "        self.id = id\n",
    "\n",
    "    def filter(self, record):\n",
    "        return record.thread == self.id\n",
    "\n",
    "\n",
    "formatter = logging.Formatter(\n",
    "    \"%(asctime)s-%(name)s-%(levelname)s-%(filename)s-%(lineno)s-%(funcName)s | %(message)s\"\n",
    ")\n",
    "\n",
    "sysout_handler = logging.StreamHandler(stdout)\n",
    "sysout_handler.setLevel(logging.CRITICAL)\n",
    "sysout_handler.setFormatter(formatter)\n",
    "\n",
    "pd_book_tools_logger: logging.Logger = logging.getLogger(\"pd_book_tools\")\n",
    "pd_book_tools_logger.setLevel(logging.DEBUG)\n",
    "if pd_book_tools_logger.hasHandlers():\n",
    "    pd_book_tools_logger.handlers.clear()\n",
    "\n",
    "doctr_logger: logging.Logger = logging.getLogger(\"doctr\")\n",
    "doctr_logger.setLevel(logging.ERROR)\n",
    "if doctr_logger.hasHandlers():\n",
    "    doctr_logger.handlers.clear()\n",
    "\n",
    "matplotlib_logger: logging.Logger = logging.getLogger(\"matplotlib\")\n",
    "if matplotlib_logger.hasHandlers():\n",
    "    matplotlib_logger.handlers.clear()\n",
    "matplotlib_logger.setLevel(logging.ERROR)\n",
    "\n",
    "ipynb_labeler_logger: logging.Logger = logging.getLogger(\"data_labeler\")\n",
    "if ipynb_labeler_logger.hasHandlers():\n",
    "    ipynb_labeler_logger.handlers.clear()\n",
    "ipynb_labeler_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "logger.addHandler(sysout_handler)\n",
    "\n",
    "\n",
    "logfile = pathlib.Path(\"all-logs.log\")\n",
    "log_file_handler = logging.FileHandler(filename=logfile, mode=\"w\", encoding=\"utf-8\")\n",
    "log_file_handler.setFormatter(formatter)\n",
    "log_file_handler.setLevel(logging.DEBUG)\n",
    "pd_book_tools_logger.addHandler(log_file_handler)\n",
    "ipynb_labeler_logger.addHandler(log_file_handler)\n",
    "\n",
    "\n",
    "# logfile = pathlib.Path(\"ipynb_labeler.log\")\n",
    "# ipynb_log_file_handler = logging.FileHandler(\n",
    "#     filename=logfile, mode=\"w\", encoding=\"utf-8\"\n",
    "# )\n",
    "# # ipynb_formatter = logging.Formatter(\"%(levelname)s-%(funcName)s-%(message)s\")\n",
    "# ipynb_log_file_handler.setFormatter(formatter)\n",
    "# ipynb_log_file_handler.setLevel(logging.DEBUG)\n",
    "# ipynb_labeler_logger.addHandler(ipynb_log_file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predictor = None\n",
    "# check if file exists\n",
    "if os.path.exists(\"ml-models/detection-model-finetuned.pt\") and os.path.exists(\n",
    "    \"ml-models/recognition-model-finetuned.pt\"\n",
    "):\n",
    "    # Check if GPU is available\n",
    "    device, device_nbr = (\n",
    "        (\"cuda\", \"cuda:0\") if torch.cuda.is_available() else (\"cpu\", \"cpu\")\n",
    "    )\n",
    "    logger.info(f\"Using {device} for OCR\")\n",
    "\n",
    "    finetuned_detection = \"ml-models/detection-model-finetuned.pt\"\n",
    "    finetuned_recognition = \"ml-models/recognition-model-finetuned.pt\"\n",
    "\n",
    "    det_model = db_resnet50(pretrained=True).to(device)\n",
    "    det_params = torch_load(finetuned_detection, map_location=device_nbr)\n",
    "    det_model.load_state_dict(det_params)\n",
    "\n",
    "    vocab = \"\".join(\n",
    "        sorted(\n",
    "            dict.fromkeys(VOCABS[\"multilingual\"] + \"⸺¡¿—‘’“”′″\" + VOCABS[\"currency\"])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    reco_model = crnn_vgg16_bn(\n",
    "        pretrained=True,\n",
    "        pretrained_backbone=True,\n",
    "        vocab=vocab,  # model was fine-tuned on multilingual data with some additional unicode characters\n",
    "    ).to(device)\n",
    "    reco_params = torch_load(finetuned_recognition, map_location=device_nbr)\n",
    "    reco_model.load_state_dict(reco_params)\n",
    "\n",
    "    full_predictor = ocr_predictor(\n",
    "        det_arch=det_model,\n",
    "        reco_arch=reco_model,\n",
    "        pretrained=True,\n",
    "        assume_straight_pages=True,\n",
    "        disable_crop_orientation=True,\n",
    "    )\n",
    "\n",
    "    det_predictor = detection_predictor(\n",
    "        arch=det_model,\n",
    "        pretrained=True,\n",
    "        assume_straight_pages=True,\n",
    "    )\n",
    "\n",
    "    reco_predictor = recognition_predictor(\n",
    "        arch=reco_model,\n",
    "        pretrained=True,\n",
    "    )\n",
    "\n",
    "    full_predictor.det_predictor = det_predictor\n",
    "    full_predictor.reco_predictor = reco_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A history of the american people - projectID629292e7559a8\n",
    "# Chile and the Nitrate Fields - projectID63ac684a641d4\n",
    "# From magic to science - projectID6737b15d33ff3\n",
    "# Credulities past and present - projectID63ac6757567bd\n",
    "# French furniture and decoration (has sidenotes and footnotes) - projectID66c62fca99a93\n",
    "# The book of filial duty - projectID67658de495d0c\n",
    "project_id = \"projectID63ac684a641d4\"\n",
    "\n",
    "source_file = f\"source-pgdp-data/output/{project_id}/pages.json\"\n",
    "pgdp_export = PGDPExport.from_json_file(source_file)\n",
    "\n",
    "i = IpynbLabeler(\n",
    "    pgdp_export=pgdp_export,\n",
    "    labeled_ocr_path=Path(\"./matched-ocr\"),\n",
    "    training_set_output_path=Path(\"./ml-training\"),\n",
    "    validation_set_output_path=Path(\"./ml-validation\"),\n",
    "    monospace_font_name=\"DPSansMono\",\n",
    "    monospace_font_path=Path(\"./DPSansMono.ttf\"),\n",
    "    start_page_idx=35,\n",
    "    doctr_predictor=full_predictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# —"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
